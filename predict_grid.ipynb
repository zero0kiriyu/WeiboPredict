{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ufunc size changed, may indicate binary incompatibility. Expected 216 from C header, got 192 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4032e9f7e222>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPool\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\science\\lib\\site-packages\\catboost\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFeaturesData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEFstrType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCatBoost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum_models\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVERSION\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m__version__\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'FeaturesData'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'EFstrType'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Pool'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CatBoost'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CatBoostClassifier'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CatBoostRegressor'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CatBoostError'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CatboostError'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sum_models'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# API compatibility alias.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\science\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m \u001b[0m_catboost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_catboost_bin_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[0m_PoolBase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_catboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_PoolBase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[0m_CatBoost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_catboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_CatBoost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\science\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mget_catboost_bin_module\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mso_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mso_paths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mloaded_catboost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_catboost'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mso_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'catboost._catboost'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_catboost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mloaded_catboost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\science\\lib\\imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[1;34m(name, path, file)\u001b[0m\n\u001b[0;32m    340\u001b[0m         spec = importlib.machinery.ModuleSpec(\n\u001b[0;32m    341\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mnumpy.pxd\u001b[0m in \u001b[0;36minit _catboost\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216 from C header, got 192 from PyObject"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool ,cv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from itertools import product, chain\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "del data['Unnamed: 0']\n",
    "data['total_num'] = data['like_num']+data['repost_num']+data['comment_num']\n",
    "data['at_num'] = data.apply(lambda x:x['content'].count('@'),axis=1)\n",
    "data['hash_num'] = data.apply(lambda x:x['content'].count('#'),axis=1)\n",
    "data['has_video'] = data.apply(lambda x:0 if pd.isnull(x['video_url']) else 1,axis=1)\n",
    "data['has_image'] = data.apply(lambda x:0 if pd.isnull(x['image_url']) else 1,axis=1)\n",
    "data['is_origin'] = data.apply(lambda x:1 if pd.isnull(x['origin_weibo']) else 0,axis=1)\n",
    "data['year'] = data.apply(lambda x:pd.to_datetime(x['created_at']).year,axis=1)\n",
    "\n",
    "def judge_level(x):\n",
    "    if x['total_num']<=100:\n",
    "        return 0\n",
    "    if x['total_num']<=1000:\n",
    "        return 1\n",
    "    return 2\n",
    "data['total_class'] = data.apply(lambda x:judge_level(x),axis=1)\n",
    "\n",
    "data[['vip_level','fans_num','tweets_num','at_num','hash_num','has_video','has_image','is_origin','year']] = data[['vip_level','fans_num','tweets_num','at_num','hash_num','has_video','has_image','is_origin','year']].apply(pd.to_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#dataset = data[['class','vip_level','fans_num','tweets_num','at_num','hash_num','has_video','has_image','is_origin','year']]\n",
    "#labels = data['total_class']\n",
    "#_,x_test,_,y_test = train_test_split(dataset,labels,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([data[data.total_class == 0].sample(n=2600),data[data.total_class == 1].sample(n=2600),data[data.total_class == 2].sample(n=2600)],axis=0,ignore_index=True)\n",
    "dataset = temp[['class','vip_level','fans_num','tweets_num','at_num','hash_num','has_video','has_image','is_origin','year']]\n",
    "labels = temp['total_class']\n",
    "x_train,_,y_train,_ = train_test_split(dataset,labels,test_size=0.3,random_state=0)\n",
    "\n",
    "cat_features=['class','vip_level','has_video','has_image','is_origin','year']\n",
    "\n",
    "cv_dataset =  Pool(data=dataset,\n",
    "                  label=labels,\n",
    "                  cat_features=cat_features)\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000 ,cat_features=cat_features, task_type=\"GPU\",devices=\"0:1:2:3\",logging_level = 'silent')\n",
    "\n",
    "grid = {\n",
    "    'learning_rate': [0.001,0.005,0.01,0.05, 0.1,0.2],\n",
    "    'depth':[4, 6,8, 10],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9]\n",
    "}\n",
    "scoring_evals = {'precision': 'precision_micro', 'recall':'recall_micro' , 'f1': 'f1_micro'}\n",
    "\n",
    "grid_search =GridSearchCV(model,grid,scoring = scoring_evals)\n",
    "catboost_result = grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(temp[['class','vip_level','fans_num','tweets_num','at_num','hash_num','has_video','has_image','is_origin','year']],columns=['class','year','vip_level'])\n",
    "labels = temp['total_class']\n",
    "x_train,_,y_train,_ = train_test_split(dataset,labels,test_size=0.3,random_state=0)\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1,criterion='gini',max_features= 'auto' ,n_estimators=1500, oob_score = True) \n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [900,1000,1100,1200,1300,1400,1500,1600],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion':['gini','entropy'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid,scoring = scoring_evals)\n",
    "randomforest_result = grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:science]",
   "language": "python",
   "name": "conda-env-science-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
